{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\envs\\politic\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\envs\\politic\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\envs\\politic\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\envs\\politic\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\envs\\politic\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\envs\\politic\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on 2020.2.12 11:00\n",
    "@author: Johnson\n",
    "\n",
    "\"\"\"\n",
    "# 先把套件匯進來\n",
    "from ckiptagger import data_utils, construct_dictionary, WS\n",
    "import csv\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "# 載入 ckiptagger 自訂詞典 KccDict2020.txt\n",
    "User_Dict = {}\n",
    "with open(\"../KCC Data/Dict/KccDict2020.txt\",\"r\", encoding='utf-8-sig') as UDicts:\n",
    "    for udic in UDicts:\n",
    "        udWord = udic.strip().split(\" \")\n",
    "        if len(udWord) > 1:\n",
    "            User_Dict[udWord[0]] = udWord[1]\n",
    "        else:\n",
    "            User_Dict[udWord[0]] = 10    # 未給定權重者一律賦予預設值 10                \n",
    "dictionary = construct_dictionary(User_Dict)\n",
    "\n",
    "ws = WS(\"D:/coding_resource/fourth_grade/politic_python/code/1_temp/code_mine/KCC Data/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------CKIPTagger Word Segment ws(str,....) + 合併同義字 + 刪除標點及停用字 ---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-25 13:40:09,508 : INFO : 已完成CkipCis  101 檔案 的斷詞\n",
      "2020-05-25 13:41:24,362 : INFO : 已完成CkipCis  201 檔案 的斷詞\n",
      "2020-05-25 13:42:40,013 : INFO : 已完成CkipCis  301 檔案 的斷詞\n",
      "2020-05-25 13:44:09,201 : INFO : 已完成CkipCis  401 檔案 的斷詞\n",
      "2020-05-25 13:45:29,779 : INFO : 已完成CkipCis  501 檔案 的斷詞\n",
      "2020-05-25 13:47:43,489 : INFO : 已完成CkipCis  601 檔案 的斷詞\n",
      "2020-05-25 13:48:58,874 : INFO : 已完成CkipCis  701 檔案 的斷詞\n",
      "2020-05-25 13:50:15,666 : INFO : 已完成CkipCis  801 檔案 的斷詞\n",
      "2020-05-25 13:51:30,700 : INFO : 已完成CkipCis  901 檔案 的斷詞\n",
      "2020-05-25 13:52:50,065 : INFO : 已完成CkipCis  1001 檔案 的斷詞\n",
      "2020-05-25 13:54:10,931 : INFO : 已完成CkipCis  1101 檔案 的斷詞\n",
      "2020-05-25 13:55:32,182 : INFO : 已完成CkipCis  1201 檔案 的斷詞\n",
      "2020-05-25 13:57:23,022 : INFO : 已完成CkipCis  1301 檔案 的斷詞\n",
      "2020-05-25 13:59:28,964 : INFO : 已完成CkipCis  1401 檔案 的斷詞\n",
      "2020-05-25 14:07:32,689 : INFO : 已完成CkipCis  1501 檔案 的斷詞\n",
      "2020-05-25 14:09:09,682 : INFO : 已完成CkipCis  1601 檔案 的斷詞\n",
      "2020-05-25 14:10:24,261 : INFO : 已完成CkipCis  1701 檔案 的斷詞\n",
      "2020-05-25 14:11:40,228 : INFO : 已完成CkipCis  1801 檔案 的斷詞\n",
      "2020-05-25 14:13:01,281 : INFO : 已完成CkipCis  1901 檔案 的斷詞\n",
      "2020-05-25 14:14:28,623 : INFO : 已完成CkipCis  2001 檔案 的斷詞\n",
      "2020-05-25 14:16:01,708 : INFO : 已完成CkipCis  2101 檔案 的斷詞\n",
      "2020-05-25 14:17:37,328 : INFO : 已完成CkipCis  2201 檔案 的斷詞\n",
      "2020-05-25 14:19:18,037 : INFO : 已完成CkipCis  2301 檔案 的斷詞\n",
      "2020-05-25 14:21:21,344 : INFO : 已完成CkipCis  2401 檔案 的斷詞\n",
      "2020-05-25 14:23:35,252 : INFO : 已完成CkipCis  2501 檔案 的斷詞\n",
      "2020-05-25 14:25:22,587 : INFO : 已完成CkipCis  2601 檔案 的斷詞\n",
      "2020-05-25 14:27:12,188 : INFO : 已完成CkipCis  2701 檔案 的斷詞\n",
      "2020-05-25 14:29:14,817 : INFO : 已完成CkipCis  2801 檔案 的斷詞\n",
      "2020-05-25 14:30:08,059 : ERROR : Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "2020-05-25 14:30:08,093 : INFO : \n",
      "Unfortunately, your original traceback can not be constructed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\Anaconda3\\envs\\politic\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-3-2df5f8c988af>\", line 26, in <module>\n",
      "    coerce_dictionary = dictionary)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\envs\\politic\\lib\\site-packages\\ckiptagger\\api.py\", line 114, in __call__\n",
      "    parital_seq_segment_list = self.model.predict_label_for_a_batch(sample_list)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\envs\\politic\\lib\\site-packages\\ckiptagger\\model_ws.py\", line 417, in predict_label_for_a_batch\n",
      "    self.w_v: w_v,\n",
      "  File \"C:\\Users\\User\\Anaconda3\\envs\\politic\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\envs\\politic\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\envs\\politic\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\envs\\politic\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\envs\\politic\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1319, in _run_fn\n",
      "    options, feed_dict, fetch_list, target_list, run_metadata)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\envs\\politic\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1407, in _call_tf_sessionrun\n",
      "    run_metadata)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\Anaconda3\\envs\\politic\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\Anaconda3\\envs\\politic\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1148, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\envs\\politic\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\envs\\politic\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\User\\Anaconda3\\envs\\politic\\lib\\inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\envs\\politic\\lib\\inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\envs\\politic\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\User\\Anaconda3\\envs\\politic\\lib\\inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\envs\\politic\\lib\\inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"C:\\Users\\User\\Anaconda3\\envs\\politic\\lib\\inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"C:\\Users\\User\\Anaconda3\\envs\\politic\\lib\\genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "csvIn = open(\"../KCC Data/News-CIS Data/NewsCis18850.csv\", 'r', newline='', encoding='utf-8-sig')\n",
    "output1 = open(\"../KCC Data/News-CIS Data/CkipNewsCis18850-KccDict2020.txt\", 'w', encoding='utf-8-sig')\n",
    "\n",
    "# 載入同義字\n",
    "combine_dict = {}\n",
    "for line in open(\"../KCC Data/Dict/KccSynonym2020.txt\", \"r\", encoding=\"utf-8-sig\"):\n",
    "    seperate_word = line.strip().split(\"\\t\")\n",
    "    num = len(seperate_word)\n",
    "    for i in range(1, num):\n",
    "        combine_dict[seperate_word[i]] = seperate_word[0]\n",
    "\n",
    "# 載入 StopWord\n",
    "stopword_lst = []\n",
    "with open(\"../KCC Data/Dict/KccStopWord2020.txt\",\"r\", encoding='utf-8-sig') as stopwords:\n",
    "    for stopword in stopwords:\n",
    "        stopword_lst.append(stopword.strip())\n",
    "\n",
    "print(\"------------CKIPTagger Word Segment ws(str,....) + 合併同義字 + 刪除標點及停用字 ---------------\")\n",
    "rowlists = csv.reader(csvIn)\n",
    "i = 0\n",
    "for row in rowlists:\n",
    "    # 刪除標點, 使用自訂強制詞典\n",
    "    strCut = ws([row[2]], \n",
    "                   sentence_segmentation=True,\n",
    "                   segment_delimiter_set = {'\"',\"\\r\\n\",\"，\",\"「\",\"」\",\",\",\"？\",'\\n', \"。\", \":\", \"?\", \"!\", \";\", \"、\"},\n",
    "                   coerce_dictionary = dictionary)\n",
    "    for word in strCut[0]:\n",
    "        # 合併同義字\n",
    "        if word in combine_dict:\n",
    "            word = combine_dict[word]\n",
    "        \n",
    "        # 刪除停用字\n",
    "        if word not in stopword_lst:\n",
    "            output1.write(word + ' ')\n",
    "    output1.write('\\n')                \n",
    "    i += 1\n",
    "    if i % 100 == 0:\n",
    "        logging.info(\"已完成CkipCis  %d 檔案 的斷詞\" % (i + 1))\n",
    "output1.close()\n",
    "csvIn.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
