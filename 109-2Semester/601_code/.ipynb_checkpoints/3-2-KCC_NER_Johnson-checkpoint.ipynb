{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  function Extract_NER():   Extract NER from receiving text list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Extract_NER(ls_textRow):\n",
    "    from ckiptagger import data_utils, construct_dictionary, WS, POS, NER\n",
    "    \n",
    "    # 載入 自訂詞典\n",
    "    User_Dict = {}\n",
    "    with open(\"../KCC Data/Dict/KccDict2020.txt\",\"r\", encoding='utf-8-sig') as UDicts:\n",
    "        for udic in UDicts:\n",
    "            udWord = udic.strip().split(\" \")\n",
    "            if len(udWord) > 1:\n",
    "                User_Dict[udWord[0]] = udWord[1]\n",
    "            else:\n",
    "                User_Dict[udWord[0]] = 10    # 未給定權重者一律賦予預設值 10                \n",
    "    dictionary = construct_dictionary(User_Dict)\n",
    " \n",
    "    ws = WS(\"D:/coding_resource/fourth_grade/politic_python/code/1_temp/code_mine/KCC Data/data\")\n",
    "    pos = POS(\"D:/coding_resource/fourth_grade/politic_python/code/1_temp/code_mine/KCC Data/data\")\n",
    "    ner = NER(\"D:/coding_resource/fourth_grade/politic_python/code/1_temp/code_mine/KCC Data/data\")\n",
    "    \n",
    "    #  ls_segRow = ws(ls_textRow) ------------   without User Dictionary\n",
    "    ls_segRow = ws(ls_textRow, \n",
    "                   sentence_segmentation=True,\n",
    "                   segment_delimiter_set = {\",\", \"。\", \":\", \"?\", \"!\", \";\", \"、\"},\n",
    "                   coerce_dictionary = dictionary)\n",
    "    #print(\"ls_segRow = \", ls_segRow)\n",
    "    #print(\"-----------------------------\")\n",
    "    \n",
    "    del ws\n",
    "    del WS\n",
    "    gc.collect()\n",
    "    ls_posRow = pos(ls_segRow)\n",
    "    del pos\n",
    "    del POS\n",
    "    gc.collect()\n",
    "    ls_nerRow = ner(ls_segRow,ls_posRow)\n",
    "    del ner\n",
    "    del NER\n",
    "    gc.collect()\n",
    "    #print(\"ls_nerRow = \", ls_nerRow)\n",
    "    #print(\"-----------------------------\")\n",
    "    return ls_nerRow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\envs\\politic\\lib\\site-packages\\ipykernel_launcher.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11557</th>\n",
       "      <td>4,1-1-1000516-1-蘇炎城-4,'這是鳳山第二公有市場，是光復後民國初期的照片，...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       0\n",
       "11557  4,1-1-1000516-1-蘇炎城-4,'這是鳳山第二公有市場，是光復後民國初期的照片，..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../KCC Data/News-CIS Data/NewsCis18850.csv\", sep='delimiter', header=None, encoding='utf-8') #匯資料\n",
    "#df = pd.read_csv(\"../KCC Data/News-CIS Data/CkipNewsCis18850-KccDict2020.txt\") #匯資料\n",
    "#df[11557]\n",
    "df.loc[[11557]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read data from csv or xlsx file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0], dtype='int64')\n",
      "-----------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\envs\\politic\\lib\\site-packages\\ipykernel_launcher.py:4: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1,2016/4/18,馬英九總統昨天上午視察衛武營藝術文化中心，文化部長洪孟啟、工程會副主...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2,2016/4/18,日本九州熊本縣接連遭強震襲擊，台灣分別捐贈熊本縣政府和日本政府款項，...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3,2016/4/18,壽山動物園為增進動物飼養福祉及保育工作，特設立「高雄市壽山動物園認養...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  1,2016/4/18,馬英九總統昨天上午視察衛武營藝術文化中心，文化部長洪孟啟、工程會副主...\n",
       "1  2,2016/4/18,日本九州熊本縣接連遭強震襲擊，台灣分別捐贈熊本縣政府和日本政府款項，...\n",
       "2  3,2016/4/18,壽山動物園為增進動物飼養福祉及保育工作，特設立「高雄市壽山動物園認養..."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#讀檔\n",
    "\n",
    "#df_file = pd.read_csv(r\"../KCC Data/NewsCisTest.csv\")\n",
    "df_file = pd.read_csv(\"../KCC Data/News-CIS Data/NewsCisTest.csv\",sep='delimiter', header=None, encoding='utf-8')\n",
    "print(df_file.columns)\n",
    "print(\"-----------------------------------------------------------\")\n",
    "df_file.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1,2016/4/18,馬英九總統昨天上午視察衛武營藝術文化中心，文化部長洪孟啟、工程會副主...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2,2016/4/18,日本九州熊本縣接連遭強震襲擊，台灣分別捐贈熊本縣政府和日本政府款項，...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3,2016/4/18,壽山動物園為增進動物飼養福祉及保育工作，特設立「高雄市壽山動物園認養...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4,2016/4/17,日本九州熊本地震災情慘重，高雄市長陳菊昨天說，她將率先捐出一月所得；...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5,2016/4/17,睽違超過半世紀，緬甸官方代表一行人，包含三位緬甸聯邦議會議員、美國農...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6,2016/4/16,高雄翻轉須新政府全面力挺高雄市長陳菊日前在市議會做施政報告時指出，翻...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7,2016/4/16,高雄市長陳菊昨前往東台精機參訪，她表示，高雄鼓勵傳統產業升級與研發，...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8,2016/4/16,交通局委託民間公司進行民調，昨天公布民調結果，近三個月搭乘過公車的民...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9,2016/4/18,台塑企業回饋地方藝文活動，週六晚間在高雄市仁武區運動公園登場，明華園...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10,2016/4/18,國民黨不分區立委陳宜民在鳳山地區成立的聯合服務處日前揭牌成立，服務...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7287,2-8-1071023-4-周玲妏-1,'周議員玲妏：謝謝議長，今天是這個任期的最...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7288,2-8-1071023-4-周玲妏-2,'第二個，特色公園，我想秘書長阿喬以前在當...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7289,2-8-1071023-4-周玲妏-3,'第三點，65歲以上的人口多了，老人家多了...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7290,2-8-1071023-4-周玲妏-4,'第五個，我要講騎樓的故事，台灣舊社區的演...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7291,2-8-1071023-4-周玲妏-5,'路平，大家講太多了，我就不用再講，我想這...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7292,2-8-1071023-4-周玲妏-6,'周議員玲妏：好，謝謝。接下來一點點時間，...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7293,2-8-1071023-4-周玲妏-7,'另外一個部分包含停車的問題，這個也是我一...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7294,2-8-1071023-4-周玲妏-8,'我再補充一下剛提到坑洞的部分，我最近跟工...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7295,2-8-1071023-4-周玲妏-9,'其他的問題，老實說有些真的講起來有點複雜...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7296,2-8-1071023-4-周玲妏-10,'特色公園的部分，我們也都持續在努力，當...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Text\n",
       "0   1,2016/4/18,馬英九總統昨天上午視察衛武營藝術文化中心，文化部長洪孟啟、工程會副主...\n",
       "1   2,2016/4/18,日本九州熊本縣接連遭強震襲擊，台灣分別捐贈熊本縣政府和日本政府款項，...\n",
       "2   3,2016/4/18,壽山動物園為增進動物飼養福祉及保育工作，特設立「高雄市壽山動物園認養...\n",
       "3   4,2016/4/17,日本九州熊本地震災情慘重，高雄市長陳菊昨天說，她將率先捐出一月所得；...\n",
       "4   5,2016/4/17,睽違超過半世紀，緬甸官方代表一行人，包含三位緬甸聯邦議會議員、美國農...\n",
       "5   6,2016/4/16,高雄翻轉須新政府全面力挺高雄市長陳菊日前在市議會做施政報告時指出，翻...\n",
       "6   7,2016/4/16,高雄市長陳菊昨前往東台精機參訪，她表示，高雄鼓勵傳統產業升級與研發，...\n",
       "7   8,2016/4/16,交通局委託民間公司進行民調，昨天公布民調結果，近三個月搭乘過公車的民...\n",
       "8   9,2016/4/18,台塑企業回饋地方藝文活動，週六晚間在高雄市仁武區運動公園登場，明華園...\n",
       "9   10,2016/4/18,國民黨不分區立委陳宜民在鳳山地區成立的聯合服務處日前揭牌成立，服務...\n",
       "10  7287,2-8-1071023-4-周玲妏-1,'周議員玲妏：謝謝議長，今天是這個任期的最...\n",
       "11  7288,2-8-1071023-4-周玲妏-2,'第二個，特色公園，我想秘書長阿喬以前在當...\n",
       "12  7289,2-8-1071023-4-周玲妏-3,'第三點，65歲以上的人口多了，老人家多了...\n",
       "13  7290,2-8-1071023-4-周玲妏-4,'第五個，我要講騎樓的故事，台灣舊社區的演...\n",
       "14  7291,2-8-1071023-4-周玲妏-5,'路平，大家講太多了，我就不用再講，我想這...\n",
       "15  7292,2-8-1071023-4-周玲妏-6,'周議員玲妏：好，謝謝。接下來一點點時間，...\n",
       "16  7293,2-8-1071023-4-周玲妏-7,'另外一個部分包含停車的問題，這個也是我一...\n",
       "17  7294,2-8-1071023-4-周玲妏-8,'我再補充一下剛提到坑洞的部分，我最近跟工...\n",
       "18  7295,2-8-1071023-4-周玲妏-9,'其他的問題，老實說有些真的講起來有點複雜...\n",
       "19  7296,2-8-1071023-4-周玲妏-10,'特色公園的部分，我們也都持續在努力，當..."
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_file.columns = ['index','file', 'text']\n",
    "df_file.columns = ['Text']\n",
    "df_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['index', 'file', 'Text', 'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5',\n",
      "       'Unnamed: 6', 'Unnamed: 7'],\n",
      "      dtype='object')\n",
      "-----------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016/4/18</td>\n",
       "      <td>馬英九總統昨天上午視察衛武營藝術文化中心，文化部長洪孟啟、工程會副主委顏久榮及高雄市副市長吳...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016/4/18</td>\n",
       "      <td>日本九州熊本縣接連遭強震襲擊，台灣分別捐贈熊本縣政府和日本政府款項，高雄市長陳菊、台南市長賴...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016/4/18</td>\n",
       "      <td>壽山動物園為增進動物飼養福祉及保育工作，特設立「高雄市壽山動物園認養辦法」設立動物認養專戶，...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        file                                               Text\n",
       "0  2016/4/18  馬英九總統昨天上午視察衛武營藝術文化中心，文化部長洪孟啟、工程會副主委顏久榮及高雄市副市長吳...\n",
       "1  2016/4/18  日本九州熊本縣接連遭強震襲擊，台灣分別捐贈熊本縣政府和日本政府款項，高雄市長陳菊、台南市長賴...\n",
       "2  2016/4/18  壽山動物園為增進動物飼養福祉及保育工作，特設立「高雄市壽山動物園認養辦法」設立動物認養專戶，..."
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#讀檔\n",
    "\n",
    "df_file = pd.read_csv(\"../KCC Data/News-CIS Data/NewsCisTest.csv\")\n",
    "print(df_file.columns)\n",
    "print(\"-----------------------------------------------------------\")\n",
    "\n",
    "#因為資料太多了，所以先選1000筆來跑\n",
    "df_file = df_file.iloc[0:100, [1,2]]\n",
    "df_file.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.  Main function:\n",
    "### 2.1  Pass text data to function \"Extract_NER\" by row\n",
    "### 2.2  Integrate every 10 NER return rows into one data frame  \n",
    "### 2.3  Write frame into small csv after droping duplicate, locating class, filtering short NER, sorting by class.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 欄位筆數 =  20\n",
      "------------------------------------------\n",
      "Row No =  0\n",
      "Row No =  1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-c9899540337f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;31m# print(\"ls_dfRow = \", ls_dfRow)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Row No = \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mentity_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExtract_NER\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mls_dfRow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentity_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mseg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mentity_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-32-4bfee7037bf1>\u001b[0m in \u001b[0;36mExtract_NER\u001b[1;34m(ls_textRow)\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;32mdel\u001b[0m \u001b[0mPOS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[0mls_nerRow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mls_segRow\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mls_posRow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m     \u001b[1;32mdel\u001b[0m \u001b[0mner\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;32mdel\u001b[0m \u001b[0mNER\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\politic\\lib\\site-packages\\ckiptagger\\api.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, word_sentence_list, pos_sentence_list, character_normalization, batch_sentences, batch_characters)\u001b[0m\n\u001b[0;32m    318\u001b[0m                 \u001b[0mparital_label_sentence_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msample_list\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 320\u001b[1;33m                 \u001b[0mparital_label_sentence_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_label_for_a_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    321\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mpartial_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m                 \u001b[0mlabel_sentence_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparital_label_sentence_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpartial_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\politic\\lib\\site-packages\\ckiptagger\\model_ner.py\u001b[0m in \u001b[0;36mpredict_label_for_a_batch\u001b[1;34m(self, sample_list)\u001b[0m\n\u001b[0;32m    424\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_v\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mc_v\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw_k\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mw_k\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 426\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw_v\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mw_v\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    427\u001b[0m             }\n\u001b[0;32m    428\u001b[0m         )\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\politic\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\politic\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\politic\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\politic\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1332\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\politic\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\politic\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1409\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#逐筆傳遞欄位 \"text\"\n",
    "#df_text = df_file[\"Text\"]\n",
    "df_text = df_file[\"Text\"]\n",
    "print(\"Text 欄位筆數 = \",len(df_text))\n",
    "print(\"------------------------------------------\")\n",
    "ls_class = list()\n",
    "ls_ner = list()\n",
    "fileCunt = 0\n",
    "rowCunt = 0\n",
    "for i in range(len(df_text)):\n",
    "# for i in range(6):\n",
    "    rowCunt += 1\n",
    "    ls_dfRow = [df_text[i]]\n",
    "    # print(\"ls_dfRow = \", ls_dfRow)\n",
    "    print(\"Row No = \",str(i))\n",
    "    entity_list = Extract_NER(ls_dfRow)\n",
    "    for j in range(len(entity_list[0])):\n",
    "        seg = entity_list[0].pop()\n",
    "        # print(\"seg = \",seg)\n",
    "        ls_class.append(seg[2])\n",
    "        ls_ner.append(seg[3])\n",
    "    #print(\"===========================================\")\n",
    "    #print(\"ls_class = \",ls_class)\n",
    "    #print(\"ls_ner = \",ls_ner)\n",
    "    # if i == 5 or rowCunt == 2:\n",
    "    if i == (len(df_text)-1) or rowCunt == 10:\n",
    "        fileCunt += 1\n",
    "        extract_df = pd.DataFrame({'Class':ls_class, 'NER':ls_ner})\n",
    "        deDup_df = extract_df.drop_duplicates().copy()\n",
    "        del extract_df\n",
    "        cate_df = deDup_df.loc[deDup_df['Class'].isin(['LOC','PERSON', 'ORG', 'LAW', 'EVENT','GPE','NORP'])].copy()\n",
    "        del deDup_df\n",
    "        filt_df = cate_df[cate_df['NER'].map(len) >= 2].copy()\n",
    "        del cate_df\n",
    "        NER_df = filt_df.sort_values(by=['Class']).copy()\n",
    "        del filt_df\n",
    "        #print(\"__________________________________________________________\")  \n",
    "        #print(NER_df)\n",
    "        print(\"fileCunt No = \",str(fileCunt))\n",
    "        # NER_df.to_csv(r\"News Data\\News NER Out\\\\NewsNER870_\" + str(fileCunt)+ \".csv\")\n",
    "        NER_df.to_csv(r\"ner out/NerTest_\" + str(fileCunt)+ \".csv\")\n",
    "        rowCunt = 0\n",
    "print(\"=====================================================================\")\n",
    "print(\"Totle NER Files = \",fileCunt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Integrate all csv files into single data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "# import pandas as pd\n",
    "\n",
    "# path = r'News Data\\News NER OUT'\n",
    "path = r'ner out'\n",
    "allFiles = glob.glob(\"{}/*.csv\".format(path))\n",
    "li = []\n",
    "for filename in allFiles:\n",
    "    df = pd.read_csv(filename, index_col=0, header=0)\n",
    "    li.append(df)\n",
    "\n",
    "nerFrame = pd.concat(li, axis=0, ignore_index=True)\n",
    "print(len(nerFrame))\n",
    "nerFrame.groupby('Class').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Drop duplicates, group by class and write into csv file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddFrame = nerFrame.drop_duplicates().copy()\n",
    "print(len(ddFrame))\n",
    "ddFrame.groupby('Class').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ddFrame.sort_values(by=['Class']).to_csv(r\"News Data\\News NER OUT\\\\NewsNER.csv\")\n",
    "ddFrame.sort_values(by=['Class']).to_csv(r\"ner out/NerTest.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
